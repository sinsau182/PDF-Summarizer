import type { ChatCompletionStreamResponseDelta } from "./ChatCompletionStreamResponseDelta";
/**
 * Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
 */
export type CreateChatCompletionStreamResponse = {
    /**
     * A unique identifier for the chat completion. Each chunk has the same ID.
     */
    id: string;
    /**
     * A list of chat completion choices. Can be more than one if `n` is greater than 1.
     */
    choices: Array<{
        delta: ChatCompletionStreamResponseDelta;
        /**
         * The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
         * `length` if the maximum number of tokens specified in the request was reached,
         * `content_filter` if content was omitted due to a flag from our content filters,
         * or `function_call` if the model called a function.
         *
         */
        finish_reason: "stop" | "length" | "function_call" | "content_filter" | null;
        /**
         * The index of the choice in the list of choices.
         */
        index: number;
    }>;
    /**
     * The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
     */
    created: number;
    /**
     * The model to generate the completion.
     */
    model: string;
    /**
     * The object type, which is always `chat.completion.chunk`.
     */
    object: string;
};
