import { Asset, BaseEngine } from "../generated/assetLake";
import { ListTunesResponse, LoraTuneCheckpoint, LoraTuneFile, Tune, TuneType } from "../generated/fineTuning";
import { Client } from "./client";
export declare class ListTunesRequest {
    /**
     * Tune name, alphanumeric, -, and _ allowed.
     */
    name?: string;
    /**
     * {@link TuneType} - a valid tune_type, such as "lora_tune"
     */
    tune_type?: TuneType;
    /**
     * ID of base checkpoint as a string, or the {@link Asset} object representing the
     * checkpoint.
     */
    base_checkpoint?: string | Asset;
    /**
     * Either a string array or a string representing trigger words.
     */
    trigger_words?: string[] | string;
    /**
     * {@link BaseEngine} of assets such as "image/stable-diffusion-v1-5"
     */
    engine?: BaseEngine;
    /**
     * Max number of tunes to return.
     */
    limit?: number;
    /**
     * Where to start including next list of assets
     */
    offset?: number;
    constructor(request: Record<string, any>);
}
/**
 * The create tune request.  If assets from the asset library are used to create
 * the files as a list or a string of asset_ids, then the caption will
 * automatically be set to trigger_words[0].
 */
export declare class CreateTuneRequest {
    /**
     * Continue fine-tuning if any asset was rejected.
     */
    continue_on_rejection?: boolean | null;
    /**
     * Description for the tune.
     */
    description?: string | null;
    /**
     * Details of the tune.
     */
    details: LoraTuneInput;
    /**
     * The name of the tune.
     */
    name: string;
    constructor(request: Record<string, any>);
}
export declare class LoraTuneInput {
    /**
     * The base checkpoint used for this LoRA Tune.
     */
    base_checkpoint: LoraTuneCheckpoint | Asset;
    /**
     * The files used for this LoRA Tune.  If an Array of strings containing
     * asset IDs are used or an array of assets, the caption will be set to
     * `trigger_words[0]` in the request..
     */
    files: Array<LoraTuneFile> | Array<Asset> | Array<string>;
    /**
     * The seed used for this LoRA Tune.
     */
    seed?: number | null;
    /**
     * The number of steps used for this LoRA Tune.
     */
    steps: number;
    /**
     * The trigger words used for this tune. As of now, only one trigger word is supported. `List` is used for future-proofing.
     */
    trigger_words: Array<string>;
    /**
     * Tune type.  Valid options include "lora_tune".
     */
    tune_type?: any;
    constructor(details: Record<string, any>);
}
/**
 * The FineTuningClient class.  Generally accessed through the client through
 * `client.tune`, but can be instantiated directly if desired.
 *
 * This client allows tuning loras using assets created in AssetLibrary.
 */
export declare class FineTuningClient {
    readonly client: Client;
    readonly endpoint: string;
    constructor(client: Client, endpoint?: string);
    /**
     * Get a single tune.
     *
     * @param id - The tune ID of the tune being requested.
     *
     * @throws {@link OctoAIValidationError} - if no token was found when creating
     * the {@link Client} class, or if an empty string is provided for id.
     */
    get(id: string): Promise<Tune>;
    /** @private */
    validateName(name: string): void;
    /**
     * List tunes based on the search parameters provided.  Array of tunes can be
     * accessed in response's `data` field.
     *
     * @remarks
     * This method is used with the {@link ListTunesRequest} class to query
     * the tunes and return.  If there are more tunes, the {@link ListTunesResponse}
     * will return `true` for has_more as well as the `total` number of tunes.
     *
     * You can search by `name`, `tune_type` such as "lora_tune", `engine` such as
     * "image/controlnet-sdxl", specific trigger words, set a `limit`, or
     * start the next request at a certain `offset` for larger requests.
     *
     * An example of how to request your tunes for Stable Diffusion is below:
     * ```
     *   const client = new Client(process.env.OCTOAI_TOKEN);
     *   const sdTunesResp = await client.tune.list({
     *     engine: "image/stable-diffusion-v1-5",
     *   });
     *   const sdTunes = sdTunesResp.data;
     * ```
     *
     * @param request - {@link ListTunesRequest} - parameters to use to filter
     * tunes in response.
     *
     * @throws {@link OctoAIValidationError} if there isn't a token set in the client.
     */
    list(request: ListTunesRequest): Promise<ListTunesResponse>;
    /**
     * Delete a tune.
     *
     * @param id - ID of tune to be deleted.
     *
     * @throws {@link OctoAIValidationError} if no token was found when creating
     * the {@link Client} class or if id is invalid.
     *
     * @remarks
     * Will throw client or server errors if the deletion requests fails.
     */
    delete(id: string): Promise<void>;
    /**
     * Cancel a tune.
     *
     * @param id - ID of tune to be deleted.
     *
     * @throws {@link OctoAIValidationError} if no token was found when creating
     * the {@link Client} class or if id is invalid.
     *
     * @remarks
     * Will throw client or server errors if the cancellation request fails.
     */
    cancel(id: string): Promise<void>;
    /**
     * Creates a finetuning job, then returns the {@link Tune}.
     *
     * @param request - {@link CreateTuneRequest}
     *
     * @throws {@link OctoAIValidationError} if no token was found when creating
     * the {@link Client} class.
     *
     * @remarks
     * This is used with {@link CreateTuneRequest}.  This method uses assets, such
     * as files, created in {@link AssetLibrary} to tune a LoRA.
     *
     * A code snippet of how to use this method to create a Stable Diffusion V1.5
     * LoRA is below:
     * ```
     *     import { Client, Asset } from "@octoai/client";
     *
     *     const client = new Client(process.env.OCTOAI_TOKEN);
     *
     *    const checkpoint = await (client.asset.list({
     *         is_public: true,
     *         owner: "octoai",
     *         name: "default-sd15",
     *     })).then(r => r.data[0]);
     *
     *    let assets: Asset[] = [];
     *    // It's recommended tunes include at least 5 images
     *    for (let i = 0; i < 2; i++) {
     *        const asset = await client.asset.create({
     *            name: `test_poodle_${i}`,
     *            file: `test_assets/mitchi${i}.jpg`,
     *            data: {file_format: "jpg"},
     *            asset_type: "file",
     *            description: "an sks3 poodle"
     *        });
     *        assets.push(asset);
     *     }
     *
     *     console.log(JSON.stringify(assets, undefined, 4));
     *
     *     const tune = await client.tune.create({
     *      name: "test-sks3-poodle-sd15",
     *      description: "sks3 poodle",
     *       details: {
     *         base_checkpoint: checkpoint,
     *         files: assets,
     *         steps: 500,
     *         tune_type: "lora_tune",
     *         trigger_words: ["sks3"],
     *      });
     *
     *     console.log(JSON.stringify(tune, undefined, 4));
     * ```
     */
    create(request: CreateTuneRequest): Promise<Tune>;
    validateId(id: string): void;
}
